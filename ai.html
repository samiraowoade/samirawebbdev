<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" type="text/css" href="css/style.css">
    <link rel="stylesheet" type="text/css" href="css/grid.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <!-- Font för titlen (logga)-->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Arvo&display=swap" rel="stylesheet">
    <!--Font för "subheadings"-->
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Alegreya+Sans+SC:ital,wght@1,100&display=swap" rel="stylesheet">
    
    <title>AI</title>
    </head>
  <body>

    <h1 class="bigtitle2"> &lt;h1&gt; Artificial Intelligence &lt;/h1&gt; </h1></h1>


<nav class="flexbox"> <!-- Navigation, this is going to be the menu-->


    <a class="active" href="index.html">Home</a>
    <ul>
      <!-- An unordered list, which is going to form the basis for our menu.-->
     
             <li> <a class="diff" href="ai.html"> AI </a></li>
             <li> <a class="diff" href="robotics.html"> Robotics </a></li>
             <li> <a class="diff" href="techfails.html"> Tech Fails </a></li>
             <li> <a class="diff" href="upandcoming.html"> Up and Coming </a></li>
             <li> <a class="diff" href="you.html"> YOU </a></li>
     
        </ul>

     
          <div class="intro">
          
          <p class="introparag"> Meta unveils "Segment Anything" AI image identification tool, but the 
            scale of the dataset used by the social giant raises  privacy concerns. With its Metaverse ambitions 
            in shambles, Meta is now looking to AI to drive its next stage of development. One of Meta’s 
            latest projects, the social media giant announced on Wednesday,  is called the Segment Anything 
            Model. Segment Anything helps users identify specific items in an image with a few clicks. 
            While still in demo mode, the company says Segment Anything can already take a photo and 
            individually identify the pixels comprising everything in the picture so that one or more items 
            can be separated from the rest of the image.</p>
            <div class="aiimage"><img src="img/robobo.jpeg" alt="More tech stuff"></div>
            <p class="bodytext">  “Segmentation—identifying which image pixels belong to an object—is a core task in computer vision and is used in a broad array of applications, from analyzing scientific imagery to editing photos,” Meta wrote in a post announcing the new model.

              Meta said creating an accurate segmentation model for specific tasks requires highly specialized work by technical experts with access to AI training infrastructure and large volumes of carefully annotated in-domain data.
              
              “We achieve greater generalization than previous approaches by collecting a new dataset of an unprecedented size.” Ross Girshick, a research scientist at Meta, told Decrypt in an email. “Crucially, in this dataset, we did not restrict the types of objects we annotated.
              
              “Thanks to the scale of the data and its generality, our resulting model shows impressive capabilities to handle types of images that were not seen during training, like ego-centric images, microscopy, or underwater photos,” Girshick added.</p>
            
          </div>
         


 </div>
 <footer class="footer2">

  <p>All rights reserved - &#169; Copyright</p>

</footer>



</body>
</html>
